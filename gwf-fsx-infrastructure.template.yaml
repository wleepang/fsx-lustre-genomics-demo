---
AWSTemplateFormatVersion: 2010-09-09
Description: >-
  (WWPS-GLS-WF-FSX-ISC) Creates Batch and FSx Lustre infrastructure for genomics
  workflows

Mappings:
  TagMap:
    default:
      architecture: "genomics-workflows"
      solution: "step-functions"
      tags:
        - Key: "architecture"
          Value: "genomics-workflows"
        - Key: "solution"
          Value: "step-functions"

Parameters:  
  WorkflowOrchestrator:
    Type: String
    Default: step-functions
    AllowedValues:
      - step-functions
  
  DockerImageAndMetadataVolumeSize:
    Type: Number
    Default: 75
    Description: >-
      Size of the docker metadata volume in GB.  Increase this value if you use
      many large containers.
  
  LaunchTemplateNamePrefix:
    Type: String
    Default: fsx-lustre-genomics
  
  S3ReferencePath:
    Type: String
    Description: >-
      Existing read-only S3 path (s3://bucket/prefix) that contains reference data.
      Will be imported into an FSx Lustre filesystem and mounted to /scratch/reference
      on worker instances.  When the workflow is complete, this filesystem is **NOT**
      archived back to S3.
    Default: s3://broad-references/hg38/v0
  
  S3SourceDataPath:
    Type: String
    Description: >-
      Existing read-only S3 path (s3://bucket/prefix) that contains source data.
      Will be imported into an FSx Lustre filesystem and mounted to /scratch/data
      on worker instances.  When the workflow is complete, this filesystem is **NOT** 
      archived back to S3.
    Default: s3://aws-batch-genomics-shared/secondary-analysis/example-files/fastq/
  
  S3WorkingPath:
    Type: String
    Default: ""
    Description: >-
      Existing S3 path (s3://bucket/[prefix]) that will be imported into an FSx 
      Lustre filesystem and mounted to /scratch/working on worker instances and 
      used as shared space for workflow outputs and results. When the workflow is
      complete, this filesystem is archived back to S3.
  
  S3WorkingPathExists:
    Type: String
    Description: Does this bucket already exist? If not, it will be created
    AllowedValues:
      - Yes
      - No
    Default: No
  
  LustreStorageCapacity:
    Type: Number
    MinValue: 1200
    Default: 3600
    Description: >-
      Capacity in GB of the Lustre filesystem. Minimum 1200, must be increased
      in increments of 1200.

Conditions:
  BucketDoesNotExist:
    Fn::Equals:
      - !Ref S3WorkingPathExists
      - No
  
  GenerateBucketName:
    Fn::Equals:
      - !Ref S3WorkingPath
      - ""

Resources:
  VpcStack:
    Type: AWS::CloudFormation::Stack
    Properties:
      TemplateURL: https://aws-quickstart.s3.amazonaws.com/quickstart-aws-vpc/templates/aws-vpc.template
      TimeoutInMinutes: 15
      Parameters:
        NumberOfAZs: "2"
        AvailabilityZones:
          Fn::Join:
            - ","
            - - !Select [ 0, !GetAZs "" ]
              - !Select [ 1, !GetAZs "" ]
      Tags: !FindInMap ["TagMap", "default", "tags"]

  IAMBatchInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - "ec2.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role"
        - "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess"
        - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"

  IAMBatchInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - Ref: IAMBatchInstanceRole
  
  IAMBatchSpotFleetRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - "spotfleet.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      ManagedPolicyArns:
      - "arn:aws:iam::aws:policy/service-role/AmazonEC2SpotFleetTaggingRole"
  
  IAMBatchServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: batch.amazonaws.com
          Action: sts:AssumeRole
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole

  S3WorkingBucket:
    Type: AWS::S3::Bucket
    Condition: BucketDoesNotExist
    DeletionPolicy: Retain
    Properties:
      BucketName:
        Fn::If:
          - GenerateBucketName
          - Fn::Join:
            - "-"
            - - "gwf-fsx-demo"
              - !Select [ 2, !Split [ "/", !Ref "AWS::StackId" ] ]
          - !Ref S3WorkingPath
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256

  FSxLustreReferenceFileSystem:
    Type: AWS::FSx::FileSystem
    Properties:
      FileSystemType: LUSTRE
      LustreConfiguration:
        ImportPath: !Ref S3ReferencePath
      StorageCapacity: !Ref LustreStorageCapacity
      SecurityGroupIds:
        - !Ref EC2BatchSecurityGroup
      SubnetIds:
        - !Sub "${VpcStack.Outputs.PrivateSubnet1AID}"
  
  FSxLustreSourceDataFileSystem:
    Type: AWS::FSx::FileSystem
    Properties:
      FileSystemType: LUSTRE
      LustreConfiguration:
        ImportPath: !Ref S3SourceDataPath
      StorageCapacity: !Ref LustreStorageCapacity
      SecurityGroupIds:
        - !Ref EC2BatchSecurityGroup
      SubnetIds:
        - !Sub "${VpcStack.Outputs.PrivateSubnet1AID}"

  FSxLustreWorkingFileSystem:
    Type: AWS::FSx::FileSystem
    Properties:
      FileSystemType: LUSTRE
      LustreConfiguration:
        ImportPath:
          Fn::If:
            - BucketDoesNotExist
            - !Sub "s3://${S3WorkingBucket}"
            - !Ref S3WorkingPath
        ExportPath:
          Fn::If:
            - BucketDoesNotExist
            - !Sub "s3://${S3WorkingBucket}"
            - !Ref S3WorkingPath
      StorageCapacity: !Ref LustreStorageCapacity
      SecurityGroupIds:
        - !Ref EC2BatchSecurityGroup
      SubnetIds:
        - !Sub "${VpcStack.Outputs.PrivateSubnet1AID}"

  EC2LaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateName: !Join ["-", [!Ref LaunchTemplateNamePrefix, !Select [2, !Split ["/", !Ref "AWS::StackId" ]]]]
      LaunchTemplateData:
        TagSpecifications:
          - ResourceType: instance
            Tags:
            - Key: architecture
              Value: !FindInMap ["TagMap", "default", "architecture"]
            - Key: solution
              Value: !Ref WorkflowOrchestrator
        BlockDeviceMappings:
          - Ebs:
              Encrypted: True
              DeleteOnTermination: True
              VolumeSize: !Ref DockerImageAndMetadataVolumeSize
              VolumeType: gp2 
            DeviceName: /dev/xvdcz
        UserData:
          Fn::Base64: !Sub |-
            MIME-Version: 1.0
            Content-Type: multipart/mixed; boundary="==BOUNDARY=="

            --==BOUNDARY==
            Content-Type: text/cloud-config; charset="us-ascii"

            packages:
            - lustre-client
            - amazon-ssm-agent

            runcmd:
            - start amazon-ssm-agent
            - mkdir -p /scratch/reference /scratch/data /scratch/working
            - mount -t lustre ${FSxLustreReferenceFileSystem}.fsx.us-west-2.amazonaws.com@tcp:/fsx /scratch/reference
            - mount -t lustre ${FSxLustreSourceDataFileSystem}.fsx.us-west-2.amazonaws.com@tcp:/fsx /scratch/data
            - mount -t lustre ${FSxLustreWorkingFileSystem}.fsx.us-west-2.amazonaws.com@tcp:/fsx /scratch/working

            --==BOUNDARY==--
  
  EC2BatchSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: SG for genomics workflows on Batch
      VpcId: !GetAtt "VpcStack.Outputs.VPCID"
  SGSSHIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref EC2BatchSecurityGroup
      IpProtocol: tcp
      FromPort: 22
      ToPort: 22
      CidrIp: 0.0.0.0/0
  SGAllTcpEgress:
    Type: AWS::EC2::SecurityGroupEgress
    Properties:
      GroupId: !Ref EC2BatchSecurityGroup
      IpProtocol: tcp
      FromPort: 0
      ToPort: 65535
      CidrIp: 0.0.0.0/0
  SGAllTcpSelfIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref EC2BatchSecurityGroup
      IpProtocol: tcp
      FromPort: 0
      ToPort: 65535
      SourceSecurityGroupId: !Ref EC2BatchSecurityGroup


  BatchSpotComputeEnv:
    Type: AWS::Batch::ComputeEnvironment
    Properties:
      ComputeEnvironmentName: !Sub 
        - spot-${StackGuid}
        - StackGuid: !Select [ 2, !Split [ "/", !Ref "AWS::StackId" ]]
      ServiceRole: !GetAtt IAMBatchServiceRole.Arn
      Type: MANAGED
      State: ENABLED
      ComputeResources:
        MinvCpus: 2
        DesiredvCpus: 2
        MaxvCpus: 256
        LaunchTemplate:
          LaunchTemplateId: !Ref EC2LaunchTemplate
        InstanceRole: !GetAtt IAMBatchInstanceProfile.Arn
        InstanceTypes:
          - optimal
        SecurityGroupIds:
          - !Ref EC2BatchSecurityGroup
        SpotIamFleetRole: !GetAtt IAMBatchSpotFleetRole.Arn
        Subnets: !Sub "${VpcStack.Outputs.PrivateSubnet1AID}, ${VpcStack.Outputs.PrivateSubnet2AID}"
        Type: SPOT
        Tags:
          Name: !Sub
            - batch-spot-worker-${StackGuid}
            - StackGuid: !Select [ 2, !Split [ "/", !Ref "AWS::StackId" ]]

  BatchDefaultQueue:
    Type: AWS::Batch::JobQueue
    Properties:
      JobQueueName: !Sub
        - default-${StackGuid}
        - StackGuid: !Select [ 2, !Split [ "/", !Ref "AWS::StackId" ]]
      Priority: 1
      State: ENABLED
      ComputeEnvironmentOrder:
        - Order: 1
          ComputeEnvironment: !Ref BatchSpotComputeEnv

Outputs:
  BatchJobQueue:
    Value: !Ref BatchDefaultQueue
    Export:
      Name: !Sub "${AWS::StackName}-BatchJobQueue"
    Description: >
      AWS Batch Job Queue used for workflow
  
  FSxReferenceData:
    Value: !Ref FSxLustreReferenceFileSystem
    Export:
      Name: !Sub "${AWS::StackName}-FSxReferenceData"
    Description: >
      FSx Lustre file system for reference data.  Considered read-only by the workflow.
  
  FSxSourceData:
    Value: !Ref FSxLustreSourceDataFileSystem
    Export:
      Name: !Sub "${AWS::StackName}-FSxSourceData"
    Description: >
      FSx Lustre file system used for source / input data to the workflow.
      Considered read-only by the workflow.

  FSxWorkingData:
    Value: !Ref FSxLustreWorkingFileSystem
    Export:
      Name: !Sub "${AWS::StackName}-FSxWorkingData"
    Description: >
      FSx Lustre file system used for workflow generated output.
      When the workflow is complete, any data written to this filesystem will be
      archived back to the S3 path specified as its data repository.
  
  S3WorkingData:
    Value:
      Fn::If:
        - BucketDoesNotExist
        - !Sub "s3://${S3WorkingBucket}"
        - !Ref S3WorkingPath
    Export:
      Name: !Sub "${AWS::StackName}-S3WorkingData"
    Description: >
      S3 data repository used for the FSx Lustre filesysme for workflow generated output.
      When the workflow is complete, all results will be archived here.
...
